# Prompt: Global Refactoring and Feature Expansion Plan for AutomaTeX (Tkinter + LLM)

You are a senior AI engineer and software architect with deep experience in:

-   Natural Language Processing and text generation.
-   Desktop UI frameworks, especially Tkinter.
-   LLM integration and prompt engineering (e.g., Gemini, OpenAI, local models).
-   Software modularity, maintainability, and performance.
-   Tools and workflows for academic and technical writing (especially LaTeX).

You are auditing and upgrading AutomaTeX, a local desktop application for intelligent LaTeX editing. The application is written in **Python 3.10+** with a GUI in **Tkinter** and integrates with an LLM for advanced editing assistance.

---

## Current Features (Baseline to Preserve and Enhance)

-   Tkinter-based GUI with a multi-tab text editor.
-   LaTeX syntax highlighting.
-   LLM-powered features: text completion, rephrasing, LaTeX error debugging, and content generation.
-   Integrated live PDF preview using SumatraPDF.
-   Smart image pasting: automatically creates structured directories and generates LaTeX `figure` environments.
-   Automated cleanup of unused image files upon saving.
-   A navigable document outline based on sectioning commands.
-   Custom snippet management and insertion.
-   Basic theme support (light/dark modes).

---

## Your Task

Design a **comprehensive, intelligent improvement plan** across all dimensions of the application. The goal is to transform the current application from a functional tool into a robust, maintainable, and feature-rich platform for LaTeX authors.

---

### 1. üß† Intelligent Editing & Document Logic

This section focuses on making the editor deeply aware of the document's structure and content, moving beyond simple text manipulation.

-   **Semantic Document Model:**
    -   **What:** Instead of just parsing section titles, build an internal model of the entire document that understands relationships between labels, citations, figures, tables, and references.
    -   **Why:** This enables powerful features like autocompleting `\ref{...}` and `\cite{...}` commands, detecting undefined or duplicate labels in real-time, and providing much richer context to the LLM.

-   **Proactive Error & Warning System:**
    -   **What:** Implement a background checker that detects common LaTeX anti-patterns: mismatched `\begin{...}`/`\end{...}` blocks, use of deprecated packages, or missing bibliography entries.
    -   **Why:** Reduces the user's cognitive load and prevents compilation failures by catching errors before the user even tries to compile. Warnings can be displayed in the UI gutter or a dedicated "Problems" panel.

-   **Adaptive User Preferences:**
    -   **What:** The application could learn a user's common custom commands, formatting preferences, or frequently used packages.
    -   **Why:** Allows for more personalized and efficient assistance, such as prioritizing certain packages in autocompletion or suggesting user-defined environments.

-   **Enhanced Context Management for LLM:**
    -   **What:** Develop a more sophisticated strategy for building the LLM context window. Instead of just sending the surrounding text, include the document preamble, relevant referenced figures/tables, or bibliography entries.
    -   **Why:** Dramatically improves the quality and relevance of LLM-generated content, as the model has a true understanding of the document's dependencies.

---

### 2. üí¨ LLM Integration & Prompt Engineering

This section aims to refine the LLM's role, making it a more versatile and powerful assistant.

-   **User-Customizable Prompt Library:**
    -   **What:** Move beyond the hardcoded `default_prompts.json`. Create a user-friendly interface where users can create, edit, and assign shortcuts to their own LLM prompts (e.g., a prompt to "Convert this bullet list into a two-column table").
    -   **Why:** Empowers users to tailor the LLM's capabilities to their specific workflow and writing needs, making the tool infinitely more flexible.

-   **LLM-Powered Document Review:**
    -   **What:** Introduce a feature to perform a "full document review." The LLM would read the entire text and provide high-level feedback on clarity, style, consistency, and structure.
    -   **Why:** Provides a "second pair of eyes" to help users improve the quality of their writing, catching awkward phrasing or inconsistencies a human might miss.

-   **Interactive LLM Chat Panel:**
    -   **What:** Add a dedicated chat panel to the UI. Users can have a persistent, back-and-forth conversation about their document, ask for help, or request complex, multi-step changes.
    -   **Why:** Creates a more natural and powerful way to interact with the LLM, moving from single-shot commands to a collaborative dialogue.

-   **LLM Task Orchestrator:**
    -   **What:** Build a module to manage complex, multi-step LLM tasks. For example, a "generate new section" command could be a workflow: (1) prompt for outline, (2) generate paragraph text, (3) generate a placeholder figure, (4) add a descriptive caption.
    -   **Why:** Automates complex and repetitive tasks, significantly speeding up the writing process.

---

### 3. üñº GUI / UX (Tkinter)

This section focuses on improving the user experience by making the interface more intuitive, informative, and modern.

-   **UI Component Refactoring:**
    -   **What:** Break down monolithic UI files like `interface.py` into smaller, self-contained modules for each major UI component (e.g., `ui/menubar.py`, `ui/statusbar.py`, `ui/editor_frame.py`).
    -   **Why:** Improves code organization and makes the UI easier to manage, modify, and debug.

-   **Enhanced UI Layout & Panels:**
    -   **What:** Introduce more advanced UI elements like a dedicated "Project" panel for file management, a "Problems" panel for displaying errors/warnings, and the "LLM Chat" panel.
    -   **Why:** Provides a more organized and information-rich workspace, similar to modern IDEs, without cluttering the main editor view.

-   **Visual Enhancements:**
    -   **Document Minimap:** Add a "minimap" view of the code for quick navigation in large documents.
    -   **Improved Error Highlighting:** Use gutter icons and squiggly underlines for errors/warnings instead of the current intrusive labels.
    -   **New Project Wizard:** Create a wizard to help users set up new projects from predefined templates (e.g., Article, Report, Beamer Presentation), which automatically create the necessary file structure and boilerplate code.

---

### 4. üß± Architecture

This section outlines a plan to refactor the codebase for long-term stability, testability, and ease of development.

-   **Project Structure Refactoring:**
    -   **What:** Reorganize the flat file structure into a clean package layout:
        -   `autotex/`
            -   `core/`: Core application logic (`editor_logic`, `latex_compiler`).
            -   `ui/`: All Tkinter GUI components (`interface_`, dialogs, main window).
            -   `llm/`: All LLM-related logic (`llm_api_client`, `llm_prompts`).
            -   `data/`: Data models for snippets, themes, etc.
            -   `assets/`: Icons and other resources.
        -   `tests/`: Unit and integration tests.
        -   `main.py`: Application entry point.
    -   **Why:** This is a standard, professional project structure that clearly separates concerns, making the codebase much easier to navigate and maintain.

-   **Introduce Unit & Integration Testing:**
    -   **What:** Create a `tests/` directory and implement a testing suite using `pytest`. Start by testing the non-GUI logic (e.g., section extraction, image path resolution, prompt generation).
    -   **Why:** Critical for ensuring code quality, preventing regressions, and enabling confident refactoring.

-   **Dependency Injection:**
    -   **What:** Decouple the core logic from the UI and other concrete implementations. For example, `editor_logic` should not know about Tkinter widgets; it should operate on abstract interfaces.
    -   **Why:** Makes the core logic independently testable (you can "mock" the UI) and far more reusable.

-   **Abstracted LLM Backend:**
    -   **What:** Refactor `llm_api_client.py` to be an abstract base class. Create concrete implementations for different services (e.g., `GeminiClient`, `OpenAIClient`, `OllamaClient`).
    -   **Why:** Allows users to easily switch LLM providers in the settings without changing the core application logic.

---

### 5. ‚öôÔ∏è Extensibility

This section prepares the application to grow beyond its initial feature set.

-   **Plugin System:**
    -   **What:** Design a simple plugin architecture. This would allow the community to add new functionality, such as support for a new bibliography format, a custom linter, or integration with external tools like Zotero.
    -   **Why:** Future-proofs the application and allows it to adapt to a wide range of user needs without bloating the core codebase.

-   **Template & Snippet Packs:**
    -   **What:** Create a system for importing and exporting project templates and snippet collections as single files.
    -   **Why:** Allows users and institutions to easily share standardized document structures and common code snippets.

-   **Command-Line Interface (CLI):**
    -   **What:** Add a headless mode for batch operations. For example: `python main.py --compile my_document.tex` or `python main.py --check-errors my_document.tex`.
    -   **Why:** Enables automation and integration with other scripts and build systems.

---

## Suggested Implementation Order

1.  **Architecture First (High Impact, High Difficulty):**
    -   Start with the **Project Structure Refactoring** and **Unit Testing** setup. This is foundational for all future work.
    -   Introduce **Dependency Injection** for key components like the editor and LLM client.

2.  **Core Logic & UX Improvements (High Impact, Medium Difficulty):**
    -   Implement the **Semantic Document Model** and the **Proactive Error & Warning System**. This provides immediate value to the user.
    -   Refactor the UI into **separate components** and improve error visualization.

3.  **Advanced LLM Features (Medium Impact, Medium Difficulty):**
    -   Build the **Interactive LLM Chat Panel** and the **User-Customizable Prompt Library**.

4.  **Extensibility & Future-Proofing (Medium Impact, High Difficulty):**
    -   Design the **Abstracted LLM Backend** and the **Plugin System**.
    -   Add the **CLI** and **Template Pack** features.

