
"""
This module provides utility functions for interacting with the editor's content
and processing text generated by the Large Language Model (LLM).
It includes functions for extracting context and handling text overlaps.
"""
import tkinter as tk
from utils import debug_console

def extract_editor_context(editor_widget, lines_before_cursor=5, lines_after_cursor=5):
    """
    Extracts a specified number of lines of text context from the editor widget
    around the current cursor position.

    This function is useful for providing relevant surrounding text to the LLM
    when generating or completing text, without sending the entire document.

    Args:
        editor_widget (tk.Text): The Tkinter Text widget from which to extract context.
        lines_before_cursor (int, optional): The number of lines to extract before the cursor.
                                             Defaults to 5.
        lines_after_cursor (int, optional): The number of lines to extract after the cursor.
                                            Defaults to 5.

    Returns:
        str: A string containing the extracted text context, with lines separated by newlines.
             Returns an empty string if the editor widget is invalid or an error occurs.
    """
    if not editor_widget:
        debug_console.log("Editor widget is None. Cannot extract context.", level='WARNING')
        return ""

    try:
        # Get the current cursor position (e.g., "line.char").
        cursor_index = editor_widget.index(tk.INSERT)
        # Extract the current line number from the cursor index.
        current_line_number = int(cursor_index.split(".")[0])

        # Get the index of the last character in the document to determine total lines.
        last_line_index_str = editor_widget.index("end-1c")
        # Calculate total lines, handling empty documents where "end-1c" might be "1.0".
        total_lines_in_document = int(last_line_index_str.split(".")[0]) if last_line_index_str != "1.0" or editor_widget.get("1.0", "1.end").strip() else 0

        # Determine the starting and ending line numbers for context extraction.
        # Ensure they are within valid document bounds (1 to total_lines_in_document).
        start_line_for_context = max(1, current_line_number - lines_before_cursor)
        end_line_for_context = min(total_lines_in_document, current_line_number + lines_after_cursor)

        # Extract each line within the determined range and join them with newlines.
        context_lines = [editor_widget.get(f"{i}.0", f"{i}.end") for i in range(start_line_for_context, end_line_for_context + 1)]
        return "\n".join(context_lines)
    except Exception as e:
        debug_console.log(f"An error occurred while extracting editor context: {e}", level='ERROR')
        return ""

def remove_prefix_overlap_from_completion(text_before_completion, llm_generated_completion):
    """
    Removes redundant overlapping text from the beginning of an LLM-generated completion.

    Sometimes, an LLM might start its completion by repeating a portion of the input
    text it was given. This function identifies and removes such overlaps to ensure
    a clean and natural continuation of the text.

    Args:
        text_before_completion (str): The text that was provided to the LLM as context
                                      immediately preceding the desired completion point.
        llm_generated_completion (str): The raw text generated by the LLM.

    Returns:
        str: The LLM-generated completion with any overlapping prefix removed.
    """
    # Split both texts into words for easier comparison.
    words_in_context = text_before_completion.split()
    words_in_completion = llm_generated_completion.split()

    overlap_length = 0
    # Iterate to find the longest sequence of words that is a suffix of the context
    # and a prefix of the completion.
    # The loop runs from 1 up to the minimum length of the two word lists.
    for i in range(1, min(len(words_in_context), len(words_in_completion)) + 1):
        # Check if the last `i` words of the context match the first `i` words of the completion.
        if words_in_context[-i:] == words_in_completion[:i]:
            overlap_length = i # Update overlap length if a match is found.
            
    # Join the words of the completion starting from the end of the overlap.
    # .strip() is used to remove any leading/trailing whitespace that might result from joining.
    return " ".join(words_in_completion[overlap_length:]).strip()

def clean_llm_output(text: str) -> str:
    """
    Cleans raw text chunks from the LLM to remove common artifacts.
    This is intended for real-time processing of streamed chunks.
    """
    # Remove markdown code block specifiers that can appear mid-stream
    cleaned_text = text.replace("```latex", "").replace("```", "")
    return cleaned_text

def clean_full_llm_response(text: str) -> str:
    """
    Performs a final, more thorough cleaning on the fully accumulated LLM response.

    This function strips leading/trailing whitespace and removes any surrounding
    quotes (single or double) from the entire generated text block.

    Args:
        text (str): The complete, raw text generated by the LLM.

    Returns:
        str: The cleaned, final text.
    """
    # Strip leading/trailing whitespace first
    cleaned_text = text.strip()
    
    # Remove surrounding double quotes
    if cleaned_text.startswith('"') and cleaned_text.endswith('"'):
        cleaned_text = cleaned_text[1:-1]
    
    # Remove surrounding single quotes
    if cleaned_text.startswith("'") and cleaned_text.endswith("'"):
        cleaned_text = cleaned_text[1:-1]
        
    # Return the text, stripped of any remaining whitespace
    return cleaned_text.strip()

def strip_think_tags(text: str) -> str:
    """
    Removes <think> and </think> tags from the text.
    """
    import re
    return re.sub(r'</?think>', '', text).strip()
