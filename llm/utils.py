
"""
This module provides utility functions for interacting with the editor's content
and processing text generated by the Large Language Model (LLM).
It includes functions for extracting context and handling text overlaps.
"""
import tkinter as tk
from utils import logs_console

def extract_editor_context(editor_widget, lines_before_cursor=5, lines_after_cursor=5):
    """
    Extracts a specified number of lines of text context from the editor widget
    around the current cursor position.

    This function is useful for providing relevant surrounding text to the LLM
    when generating or completing text, without sending the entire document.

    Args:
        editor_widget (tk.Text): The Tkinter Text widget from which to extract context.
        lines_before_cursor (int, optional): The number of lines to extract before the cursor.
                                             Defaults to 5.
        lines_after_cursor (int, optional): The number of lines to extract after the cursor.
                                            Defaults to 5.

    Returns:
        str: A string containing the extracted text context, with lines separated by newlines.
             Returns an empty string if the editor widget is invalid or an error occurs.
    """
    if not editor_widget:
        logs_console.log("Editor widget is None. Cannot extract context.", level='WARNING')
        return ""

    try:
        # Get the current cursor position (e.g., "line.char").
        cursor_index = editor_widget.index(tk.INSERT)
        # Extract the current line number from the cursor index.
        current_line_number = int(cursor_index.split(".")[0])

        # Get the index of the last character in the document to determine total lines.
        last_line_index_str = editor_widget.index("end-1c")
        # Calculate total lines, handling empty documents where "end-1c" might be "1.0".
        total_lines_in_document = int(last_line_index_str.split(".")[0]) if last_line_index_str != "1.0" or editor_widget.get("1.0", "1.end").strip() else 0

        # Determine the starting and ending line numbers for context extraction.
        # Ensure they are within valid document bounds (1 to total_lines_in_document).
        start_line_for_context = max(1, current_line_number - lines_before_cursor)
        end_line_for_context = min(total_lines_in_document, current_line_number + lines_after_cursor)

        # Extract each line within the determined range and join them with newlines.
        context_lines = [editor_widget.get(f"{i}.0", f"{i}.end") for i in range(start_line_for_context, end_line_for_context + 1)]
        return "\n".join(context_lines)
    except Exception as e:
        logs_console.log(f"An error occurred while extracting editor context: {e}", level='ERROR')
        return ""

def remove_prefix_overlap_from_completion(text_before_completion, llm_generated_completion):
    """
    Removes redundant overlapping text from the beginning of an LLM-generated completion.

    Sometimes, an LLM might start its completion by repeating a portion of the input
    text it was given. This function identifies and removes such overlaps to ensure
    a clean and natural continuation of the text.

    Args:
        text_before_completion (str): The text that was provided to the LLM as context
                                      immediately preceding the desired completion point.
        llm_generated_completion (str): The raw text generated by the LLM.

    Returns:
        str: The LLM-generated completion with any overlapping prefix removed.
    """
    # Split both texts into words for easier comparison.
    words_in_context = text_before_completion.split()
    words_in_completion = llm_generated_completion.split()

    overlap_length = 0
    # Iterate to find the longest sequence of words that is a suffix of the context
    # Check longest matching sequence at prefix/suffix boundary
    # Loop from 1 up to minimum length of word lists
    for i in range(1, min(len(words_in_context), len(words_in_completion)) + 1):
        # Check if the last `i` words of the context match the first `i` words of the completion.
        if words_in_context[-i:] == words_in_completion[:i]:
            overlap_length = i # Update overlap length if a match is found.
            
    # Join the words of the completion starting from the end of the overlap.
    # .strip() is used to remove any leading/trailing whitespace that might result from joining.
    return " ".join(words_in_completion[overlap_length:]).strip()

def normalize_text_content(text: str) -> str:
    """
    Normalizes LLM-generated text by applying consistent cleaning rules.
    Used for both streaming chunks and final responses to ensure consistency.
    
    Args:
        text (str): Raw text from LLM
        
    Returns:
        str: Normalized text ready for display/storage
    """
    if not text:
        return ""
    
    import re
    
    # Remove markdown code blocks (common in LLM responses)
    text = re.sub(r'```(?:latex|tex|LaTeX)?\s*', '', text)
    text = text.replace('```', '')
    
    # Remove think tags (some models use these)
    text = re.sub(r'</?think>', '', text)
    
    # Remove surrounding quotes if they wrap the entire content
    text = text.strip()
    if len(text) >= 2:
        if (text.startswith('"') and text.endswith('"')) or (text.startswith("'") and text.endswith("'")):
            text = text[1:-1]
    
    # Normalize whitespace but preserve intentional LaTeX spacing
    text = text.strip()
    
    return text

def prepare_final_response(accumulated_chunks: str, final_raw_text: str) -> str:
    """
    Prepares the final response text, choosing the most appropriate source.
    Ensures consistency between streaming display and final accepted text.
    
    Args:
        accumulated_chunks (str): Text built from streaming chunks
        final_raw_text (str): Complete final text from LLM service
        
    Returns:
        str: Final normalized text for acceptance
    """
    # Use final_raw_text when available (more complete/accurate)
    # Fall back to accumulated_chunks for streaming-only scenarios
    source_text = final_raw_text if final_raw_text else accumulated_chunks
    return normalize_text_content(source_text)

def extract_json_from_llm_response(text: str) -> str:
    """
    Extracts JSON content from LLM response text, handling various formats.
    
    This function handles common LLM response patterns including:
    - JSON wrapped in markdown code blocks (```json```)
    - Raw JSON objects in text
    - Mixed text with embedded JSON
    - JSON with whitespace and newlines
    - JSON with nested objects and arrays
    
    Args:
        text (str): Raw LLM response text
        
    Returns:
        str: Extracted JSON string ready for json.loads()
        
    Raises:
        ValueError: If no valid JSON is found in the text
    """
    import re
    import json
    
    if not text:
        raise ValueError("Empty text provided")
    
    # Clean up the text - remove extra whitespace but preserve JSON structure
    text = text.strip()
    
    # Helper function to validate and return JSON
    def validate_and_return(json_text):
        try:
            json.loads(json_text)
            return json_text.strip()
        except json.JSONDecodeError:
            return None
    
    # Try code block JSON first (```json ... ```)
    code_block_patterns = [
        r'```(?:json)?\s*(\{.*?\})\s*```',  # Code block JSON object
        r'```(?:json)?\s*(\[.*?\])\s*```',  # Code block JSON array
    ]
    
    for pattern in code_block_patterns:
        match = re.search(pattern, text, re.DOTALL)
        if match:
            result = validate_and_return(match.group(1))
            if result:
                return result
    
    # Try to extract JSON objects more carefully
    # Look for balanced braces starting with {
    i = 0
    while i < len(text):
        if text[i] == '{':
            # Try to extract from this position
            brace_count = 0
            start = i
            in_string = False
            escape_next = False
            
            for j in range(i, len(text)):
                char = text[j]
                
                if escape_next:
                    escape_next = False
                    continue
                    
                if char == '\\':
                    escape_next = True
                    continue
                    
                if not in_string:
                    if char == '"':
                        in_string = True
                    elif char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            # Found complete JSON object
                            json_candidate = text[start:j+1]
                            result = validate_and_return(json_candidate)
                            if result:
                                return result
                            break
                else:
                    if char == '"':
                        in_string = False
        i += 1
    
    # Last resort: try some very basic patterns
    simple_patterns = [
        r'(\{[^{}]*"explanation"[^{}]*"corrected_code"[^{}]*\})',  # Simple single-line JSON
        r'(\{"explanation"[^}]*\})',  # Just explanation
        r'(\{"corrected_code"[^}]*\})',  # Just corrected_code
    ]
    
    for pattern in simple_patterns:
        match = re.search(pattern, text, re.DOTALL)
        if match:
            result = validate_and_return(match.group(1))
            if result:
                return result
    
    raise ValueError(f"No valid JSON found in text: {text[:200]}...")
